```{r}
library(readr)
library(dplyr)
library(SnowballC)
Farm_ads <- read_csv("Farm-ads.csv")
data <- Farm_ads
```

```{r}
library(tm)

corp <- Corpus(VectorSource(data))

corp %>% 
tm_map(stripWhitespace) 

corp %>% 
tm_map(removePunctuation) 

corp %>% 
tm_map(stemDocument)

corp <- tm_map(corp, removeWords, stopwords("english"))

tdm <- TermDocumentMatrix(corp) 






```
#Question One '
The data does not seem to be vary sparse. 50% of the term document matrix appears to be sparse. 

#Question One (continued)
To provide some intrepretation to this data, view the frequency of the term product. This suggests that the adversements were attempting to push consumer-products rather than services to the end-user. Also, it seems that a heavy concenration of products being advertised were around dogs. This can be ascertained by looking at how often the term "dog" is used along with "pet."

#Question Two
The term-document matrix is a matrix with the frequency of the terms. It holds too much data to effectively do analysis upon, so concept-document matrix is generated based on the term-document matrix. This concept is analogous to Principal Component Analysis as it pretains to dimension reduction. The concepts that are generated are meant to represent patterns described in the term-document matrix, but they are more concise and analysis can be conducted. 


```{r}
library(lsa)
tfidf <- weightTfIdf(tdm)
lsa.tfidf <- lsa(tfidf, dim = 2)
words.df <- as.data.frame(as.matrix(lsa.tfidf$dk))


label <- c(rep(0, 4142), rep(1, 4142))
training <- sample(c(1:4142), 0.6*4142)

trainData = cbind(label = label[training], words.df[training,])


reg <- glm(label ~ ., data = trainData, family = 'binomial')
pred.train <- predict(reg, type = "response")

validData = cbind(label = label[-training], words.df[-training,])
pred.test <- predict(reg, newdata = validData, type = "response")

pred.train
pred.test

while(pred.train != pred.test)
{
  
  if(pred.train == pred.test)
  {
    count = count
  }
  else{
        count = count + 1
  }
}

count
```
#Question 3
The model does not seem to be very efficent. It seems simply want to classify as being relevant to the data. It appears that the issue here is with concept-document matrix. As the function will only accept two dimensions as it is binary, it does make some sense that the resulting matrix would not be overly useful. 

#Question 4
In practice, a concept-document matrix is essentially taking the core elements of a term-document matrix and conducting dimension reduction. By looking at concepts, it is able to create more understandable results. 


