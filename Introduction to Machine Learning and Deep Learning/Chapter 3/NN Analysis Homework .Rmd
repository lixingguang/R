---
title: "Homework NN"
author: "Ryan Marinelli"
date: "7/29/2019"
output: html_document
---
```{r}
knitr::opts_knit$set(root.dir = " C:/users/Ryan/Desktop/Week 3")
library(readr)
ToyotaCorolla <- read_csv("ToyotaCorolla.csv")
data <- ToyotaCorolla 


sampleSize <- floor(0.60*nrow(data))
set.seed(1)

trainData = sample(seq_len(nrow(data)),size = sampleSize)

train <- data[trainData,]
test <- data[-trainData,]

```

```{r}
train$Age_08_04 <- ifelse(train$Age_08_04 > mean(train$Age_08_04), 1 , 0) 
train$KM <- ifelse(train$KM > mean(train$KM), 1 , 0) 
train$Fuel_Type <- ifelse(train$Fuel_Type == "Petrol", 1, 0)
train$HP <- ifelse(train$KM > mean(train$HP), 1 , 0) 
train$Quarterly_Tax <- ifelse(train$Quarterly_Tax > mean(train$Quarterly_Tax), 1 , 0)
train$Guarantee_Period <- ifelse(train$Guarantee_Period > mean(train$Guarantee_Period), 1 , 0)

test$Age_08_04 <- ifelse(test$Age_08_04 > mean(test$Age_08_04), 1 , 0) 
test$KM <- ifelse(test$KM > mean(test$KM), 1 , 0) 
test$Fuel_Type <- ifelse(test$Fuel_Type == "Petrol", 1, 0)
test$HP <- ifelse(test$KM > mean(test$HP), 1 , 0) 
test$Quarterly_Tax <- ifelse(test$Quarterly_Tax > mean(test$Quarterly_Tax), 1 , 0)
test$Guarantee_Period <- ifelse(test$Guarantee_Period > mean(test$Guarantee_Period), 1 , 0)

```


```{r}
library(neuralnet)
library(BBmisc)
norm.train <- normalize(train)
norm.test <- normalize(test)
```


```{r}
 model.1 <- neuralnet(train$Price~Age_08_04 +KM + Fuel_Type + HP + Automatic + Doors +Quarterly_Tax + Mfr_Guarantee  + Guarantee_Period + Airco + Automatic_airco + CD_Player + Powered_Windows + Sport_Model+ Tow_Bar, hidden = 2, data = train)
plot(model.1)
model.1
```
#Question One 
The MSE for the trainning set is 9.42.
```{r}
predict.train <- compute(model.1, train)
predict.train$net.result

plot(model.1, rep = "best")

pr.nn_ <- predict.train$net.result*(max(data$Price)-min(data$Price))+min(data$Price)
test.r <- (train$Price)*(max(data$Price)-min(data$Price))+min(data$Price)

MSE.nn.train <- sum((test.r - pr.nn_)^2)/nrow(train)

MSE.nn.train
```


#Question 1 
The MSE for the test set is 7.93. 
```{r}
model.2 <- neuralnet(test$Price ~Age_08_04 +KM + Fuel_Type + HP + Automatic + Doors +Quarterly_Tax + Mfr_Guarantee  + Guarantee_Period + Airco + Automatic_airco + CD_Player + Powered_Windows + Sport_Model+ Tow_Bar, hidden = 2, data = test)

predict.test <- compute(model.2, test)
predict.train$net.result

pr.nn_ <- predict.test$net.result*(max(data$Price)-min(data$Price))+min(data$Price)
test.r <- (test$Price)*(max(data$Price)-min(data$Price))+min(data$Price)

MSE.nn.test <- sum((test.r - pr.nn_)^2)/nrow(train)

MSE.nn.test

```
```{r}
model.3 <- neuralnet(test$Price ~Age_08_04 +KM + Fuel_Type + HP + Automatic + Doors +Quarterly_Tax + Mfr_Guarantee  + Guarantee_Period + Airco + Automatic_airco + CD_Player + Powered_Windows + Sport_Model+ Tow_Bar, hidden = 5, data = test)

predict.test.3 <- compute(model.3, test)
predict.test.3$net.result

pr.nn_ <- predict.test.3$net.result*(max(data$Price)-min(data$Price))+min(data$Price)
test.r <- (test$Price)*(max(data$Price)-min(data$Price))+min(data$Price)

MSE.nn.test.2 <- sum((test.r - pr.nn_)^2)/nrow(train)

MSE.nn.test.2
```

```{r}
model.4 <- neuralnet(train$Price ~Age_08_04 +KM + Fuel_Type + HP + Automatic + Doors +Quarterly_Tax + Mfr_Guarantee  + Guarantee_Period + Airco + Automatic_airco + CD_Player + Powered_Windows + Sport_Model+ Tow_Bar, hidden = 5, data = train)

predict.test.4 <- compute(model.4, train)
predict.test.4$net.result

pr.nn_ <- predict.test.4$net.result*(max(data$Price)-min(data$Price))+min(data$Price)
test.r <- (train$Price)*(max(data$Price)-min(data$Price))+min(data$Price)

MSE.nn.train.2 <- sum((test.r - pr.nn_)^2)/nrow(train)


```
```{r}
MSE.nn.train
MSE.nn.train.2
MSE.nn.test
MSE.nn.test.2
```
```
#Question 2
It appears that the error tends to level out by the time you add additional hidden layers so additional layers are likely to yield little benefit. When confront with marginal gains with increasing complexity of a model, it is best to select the most simple most model to promote parsimony. Thus, it would be supported here to select the model with a singular layer as there appears to be little to no improvement with adding subsequent layers. 

The test data in both cases as a lower RSE than the training, which is to be expected. The training data performs more poorly in both instances. 

The RSM of the validation set does not seem to improve drasitically as well to warrant increasing the number of hidden layers. 
